{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç LGBM - Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pickle as pkl\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data_tools.feature_engineering import (\n",
    "    process_paragraph,\n",
    "    paragraph_feature_engineering,\n",
    "    process_sentence,\n",
    "    sentence_feature_engineering,\n",
    "    process_word,\n",
    "    word_feature_engineering,\n",
    "    generate_tfidf_features,\n",
    "    generate_count_features,\n",
    ")\n",
    "from lib.paths import Paths\n",
    "from lib.config import config\n",
    "from lib.paths import Paths\n",
    "from lib.utils.utils import seed_everything, get_model_path\n",
    "from lib.data_tools.data import clean_text, sliding_window\n",
    "from lib.model.inference import ensemble_inference\n",
    "\n",
    "# Without the following the LGBM models can't be read\n",
    "from lib.model.utils import cohen_kappa_score, qwk_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üåé Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'microsoft_deberta-v3-xsmall'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.model.replace(\"/\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output/microsoft/deberta-v3-xsmall/microsoft_deberta-v3-xsmall_fold_0_best.pth': 0.14285714285714285,\n",
       " 'output/microsoft/deberta-v3-xsmall/microsoft_deberta-v3-xsmall_fold_1_best.pth': 0.14285714285714285,\n",
       " 'output/microsoft/deberta-v3-xsmall/microsoft_deberta-v3-xsmall_fold_2_best.pth': 0.14285714285714285,\n",
       " 'output/microsoft/deberta-v3-xsmall/microsoft_deberta-v3-xsmall_fold_3_best.pth': 0.14285714285714285,\n",
       " 'output/microsoft/deberta-v3-xsmall/microsoft_deberta-v3-xsmall_fold_4_best.pth': 0.14285714285714285,\n",
       " 'output/microsoft/deberta-v3-xsmall/microsoft_deberta-v3-xsmall_fold_5_best.pth': 0.14285714285714285,\n",
       " 'output/microsoft/deberta-v3-xsmall/microsoft_deberta-v3-xsmall_fold_6_best.pth': 0.14285714285714285}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberat_model_paths = {\n",
    "    get_model_path(i): 1 / config.n_folds for i in range(config.n_folds)\n",
    "}\n",
    "deberat_model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/LGBM/0.pkl',\n",
       " 'output/LGBM/1.pkl',\n",
       " 'output/LGBM/2.pkl',\n",
       " 'output/LGBM/3.pkl',\n",
       " 'output/LGBM/4.pkl',\n",
       " 'output/LGBM/5.pkl',\n",
       " 'output/LGBM/6.pkl',\n",
       " 'output/LGBM/7.pkl',\n",
       " 'output/LGBM/8.pkl',\n",
       " 'output/LGBM/9.pkl',\n",
       " 'output/LGBM/10.pkl',\n",
       " 'output/LGBM/11.pkl',\n",
       " 'output/LGBM/12.pkl',\n",
       " 'output/LGBM/13.pkl',\n",
       " 'output/LGBM/14.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_model_paths = [f\"output/LGBM/{i}.pkl\" for i in range(config.lgbm_n_folds)]\n",
    "lgbm_model_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíø Loading from Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™ô Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens in the tokenizer: 128003\n",
      "DebertaV2TokenizerFast(name_or_path='output/microsoft/deberta-v3-xsmall/tokenizer_v2', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t128000: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t128001: AddedToken(\"\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t128002: AddedToken(\"  \", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(Paths.TOKENIZER_PATH)\n",
    "vocabulary = tokenizer.get_vocab()\n",
    "total_tokens = len(vocabulary)\n",
    "print(\"Total number of tokens in the tokenizer:\", total_tokens)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(Paths.TEST_CSV_PATH)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚åõ Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"full_text\"] = test_df[\"full_text\"].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 182.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5, 2), (3, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sliding_window(test_df, tokenizer)\n",
    "df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeBERTa Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model 0 Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.27test_batch/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model 1 Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 28.94test_batch/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model 2 Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 30.18test_batch/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model 3 Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 31.61test_batch/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model 4 Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 29.36test_batch/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model 5 Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 28.95test_batch/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Model 6 Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 29.32test_batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>p_0</th>\n",
       "      <th>p_1</th>\n",
       "      <th>p_2</th>\n",
       "      <th>p_3</th>\n",
       "      <th>p_4</th>\n",
       "      <th>p_5</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000d118</td>\n",
       "      <td>0.117078</td>\n",
       "      <td>0.370102</td>\n",
       "      <td>0.419184</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.008851</td>\n",
       "      <td>0.003573</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fe60</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>0.219967</td>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.080437</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001ab80</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.007076</td>\n",
       "      <td>0.047527</td>\n",
       "      <td>0.407841</td>\n",
       "      <td>0.440049</td>\n",
       "      <td>0.092171</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  essay_id       p_0       p_1       p_2       p_3       p_4       p_5  score\n",
       "0  000d118  0.117078  0.370102  0.419184  0.081213  0.008851  0.003573      2\n",
       "1  000fe60  0.016278  0.219967  0.675862  0.080437  0.005159  0.002297      2\n",
       "2  001ab80  0.005337  0.007076  0.047527  0.407841  0.440049  0.092171      4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_predictions = ensemble_inference(\n",
    "    df,\n",
    "    tokenizer,\n",
    "    deberat_model_paths,\n",
    "    device,\n",
    "    logits=True,\n",
    ")\n",
    "deberta_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 33)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_features = process_paragraph(test_df)\n",
    "paragraph_features = paragraph_feature_engineering(paragraph_features)\n",
    "paragraph_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 25)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_features = process_sentence(test_df)\n",
    "sentence_features = sentence_feature_engineering(sentence_features)\n",
    "sentence_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features = process_word(test_df)\n",
    "word_features = word_feature_engineering(word_features)\n",
    "word_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 19628)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"output/LGBM/vectorizer.pkl\", \"rb\") as file:\n",
    "    vectorizer = pkl.load(file)\n",
    "    _, tfidf_features = generate_tfidf_features(test_df, vectorizer)\n",
    "    \n",
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2171)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"output/LGBM/vectorizer_cnt.pkl\", \"rb\") as file:\n",
    "    vectorizer = pkl.load(file)\n",
    "    _, count_features = generate_count_features(test_df, vectorizer)\n",
    "    \n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 21866)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = deberta_predictions.drop(columns=[\"score\"]).copy()\n",
    "\n",
    "# Merge using essay_id column\n",
    "for feature_df in [paragraph_features, sentence_features, word_features, tfidf_features, count_features]:\n",
    "    all_features = pd.merge(all_features, feature_df, on=\"essay_id\")\n",
    "\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = []\n",
    "\n",
    "for model_path in lgbm_model_paths:\n",
    "    with open(model_path, \"rb\") as file:\n",
    "        model = pkl.load(file)\n",
    "\n",
    "        probabilities.append(model.predict(all_features.drop(columns=[\"essay_id\"])) + config.lgbm_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 4.]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.mean(probabilities, axis=0)\n",
    "predictions = np.round(predictions.clip(1, 6))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"essay_id\"] = test_df[\"essay_id\"]\n",
    "submission[\"score\"] = predictions\n",
    "print(f\"Submission shape: {submission.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
