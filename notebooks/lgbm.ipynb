{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM\n",
    "\n",
    "Sources\n",
    "1. [LGBM & Deberta Explained by ZULQARNAIN ALI](https://www.kaggle.com/code/zulqarnainalipk/lgbm-deberta-explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.config import config\n",
    "from lib.paths import Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Paths.COMPETITION_TRAIN_CSV_PATH)\n",
    "test_df = pd.read_csv(Paths.COMPETITION_TEST_CSE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Spelling Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Paths.ENG_WORDS_HX, 'r') as file:\n",
    "    english_vocab = set(word.strip().lower() for word in file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_spelling_errors(text):\n",
    "    \"\"\"Uses `spacy` and list of correctly spelled english words\n",
    "    located at `Paths.ENG_WORDS_HX` to count number of spelling\n",
    "    errors.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_.lower() for token in doc]\n",
    "\n",
    "    spelling_errors = sum(\n",
    "        1 for token in lemmatized_tokens if token not in english_vocab\n",
    "    )\n",
    "\n",
    "    return spelling_errors\n",
    "\n",
    "\n",
    "count_spelling_errors(\"There is one speling error here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_dict = json.load(open(Paths.CONTRACTION_FILE_PATH, \"r\"))\n",
    "contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are not working!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_contractions(text: str, c_re=contraction_re) -> str:\n",
    "    \"\"\"Replaces contracted word/phrase with enlongated word/phrase.\"\"\"\n",
    "\n",
    "    def replace(match):\n",
    "        return contraction_dict[match.group(0)]\n",
    "\n",
    "    return c_re.sub(replace, text)\n",
    "\n",
    "expand_contractions(\"You aren't working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_HTML_tags(text: str) -> str:\n",
    "    \"\"\"Remove HTML tags from a text string\"\"\"\n",
    "    return re.sub(r\"<[^>]*>\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text: str) -> str:\n",
    "    \"\"\"Remove URLs from a text string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is example: for user'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_preprocessing(x: str) -> str:\n",
    "    x = x.lower()\n",
    "    x = remove_HTML_tags(x)\n",
    "    x = re.sub(\"@\\w+\", \"\", x)\n",
    "    x = re.sub(\"'\\d+\", \"\", x)\n",
    "    x = re.sub(\"\\d+\", \"\", x)\n",
    "    x = remove_URL(x)\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "\n",
    "data_preprocessing(\"This is 1 example: <b>https://www.kaggle.com/</b> for user @shakleen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ThisHasNoPunctuations'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punctuation(text: str) -> str:\n",
    "    \"\"\"A translator is created using str.maketrans('', '', string.punctuation), \n",
    "    which generates a translation table that maps each character in the \n",
    "    string string.punctuation to None. This effectively removes all punctuation characters.\"\"\"\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "remove_punctuation(\"This.Has!No-Punctuations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineerings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paragraph Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_paragraph(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Construct paragraphs\n",
    "    df[\"paragraph\"] = df[\"full_text\"].map(lambda x: x.split(\"\\n\\n\"))\n",
    "\n",
    "    # Have each paragraph be its own row\n",
    "    df = df.explode(\"paragraph\")\n",
    "\n",
    "    # Process Paragraph text\n",
    "    df[\"paragraph\"] = df[\"paragraph\"].map(data_preprocessing)\n",
    "    df[\"paragraph_no_punctuation\"] = df[\"paragraph\"].map(remove_punctuation)\n",
    "\n",
    "    # Calculate base stats\n",
    "    df[\"paragraph_error_count\"] = df[\"paragraph_no_punctuation\"].map(count_spelling_errors)\n",
    "    df[\"paragraph_char_count\"] = df[\"paragraph\"].map(lambda x: len(x))\n",
    "    df[\"paragraph_word_count\"] = df[\"paragraph\"].map(lambda x: len(re.findall(r'\\w+', x)))\n",
    "    df[\"paragraph_sentence_count\"] = df[\"paragraph\"].map(lambda x: len(re.findall(r'[.!?]', x)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85934, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_features = process_paragraph(train_df)\n",
    "paragraph_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>paragraph_no_punctuation</th>\n",
       "      <th>paragraph_error_count</th>\n",
       "      <th>paragraph_char_count</th>\n",
       "      <th>paragraph_word_count</th>\n",
       "      <th>paragraph_sentence_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14463</th>\n",
       "      <td>d513e3a</td>\n",
       "      <td>\"What the picture actually shows is the Martia...</td>\n",
       "      <td>2</td>\n",
       "      <td>\"thousands of anixous web surfers were waiting...</td>\n",
       "      <td>thousands of anixous web surfers were waiting ...</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12043</th>\n",
       "      <td>b0fc064</td>\n",
       "      <td>A good reason for other people to join the Sea...</td>\n",
       "      <td>3</td>\n",
       "      <td>luke joined the seagoing cowboys program becau...</td>\n",
       "      <td>luke joined the seagoing cowboys program becau...</td>\n",
       "      <td>1</td>\n",
       "      <td>301</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>25588ad</td>\n",
       "      <td>The invention of driverless cars could be a re...</td>\n",
       "      <td>3</td>\n",
       "      <td>the cost of gas can be a major problem.</td>\n",
       "      <td>the cost of gas can be a major problem</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id                                          full_text  score  \\\n",
       "14463  d513e3a  \"What the picture actually shows is the Martia...      2   \n",
       "12043  b0fc064  A good reason for other people to join the Sea...      3   \n",
       "2483   25588ad  The invention of driverless cars could be a re...      3   \n",
       "\n",
       "                                               paragraph  \\\n",
       "14463  \"thousands of anixous web surfers were waiting...   \n",
       "12043  luke joined the seagoing cowboys program becau...   \n",
       "2483             the cost of gas can be a major problem.   \n",
       "\n",
       "                                paragraph_no_punctuation  \\\n",
       "14463  thousands of anixous web surfers were waiting ...   \n",
       "12043  luke joined the seagoing cowboys program becau...   \n",
       "2483              the cost of gas can be a major problem   \n",
       "\n",
       "       paragraph_error_count  paragraph_char_count  paragraph_word_count  \\\n",
       "14463                      2                   131                    21   \n",
       "12043                      1                   301                    55   \n",
       "2483                       0                    39                     9   \n",
       "\n",
       "       paragraph_sentence_count  \n",
       "14463                         4  \n",
       "12043                         3  \n",
       "2483                          1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_features.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraph_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    feature_list = [\n",
    "        \"paragraph_error_count\",\n",
    "        \"paragraph_char_count\",\n",
    "        \"paragraph_word_count\",\n",
    "        \"paragraph_sentence_count\",\n",
    "    ]\n",
    "\n",
    "    feature_df = df.groupby(\"essay_id\")[feature_list].agg(\n",
    "        [\"mean\", \"min\", \"max\", \"sum\", \"first\", \"last\"]\n",
    "    )\n",
    "\n",
    "    feature_df = pd.concat(\n",
    "        [\n",
    "            feature_df,\n",
    "            df.groupby(\"essay_id\")[feature_list]\n",
    "            .agg([lambda x: np.quantile(x, 0.25), lambda x: np.quantile(x, 0.75)])\n",
    "            .rename(columns={\"<lambda_0>\": \"q1\", \"<lambda_1>\": \"q3\"}),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    feature_df = feature_df.set_axis(feature_df.columns.map(\"_\".join), axis=1)\n",
    "    return feature_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 33)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_features = paragraph_feature_engineering(paragraph_features)\n",
    "paragraph_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'paragraph_error_count_mean', 'paragraph_error_count_min',\n",
       "       'paragraph_error_count_max', 'paragraph_error_count_sum',\n",
       "       'paragraph_error_count_first', 'paragraph_error_count_last',\n",
       "       'paragraph_char_count_mean', 'paragraph_char_count_min',\n",
       "       'paragraph_char_count_max', 'paragraph_char_count_sum',\n",
       "       'paragraph_char_count_first', 'paragraph_char_count_last',\n",
       "       'paragraph_word_count_mean', 'paragraph_word_count_min',\n",
       "       'paragraph_word_count_max', 'paragraph_word_count_sum',\n",
       "       'paragraph_word_count_first', 'paragraph_word_count_last',\n",
       "       'paragraph_sentence_count_mean', 'paragraph_sentence_count_min',\n",
       "       'paragraph_sentence_count_max', 'paragraph_sentence_count_sum',\n",
       "       'paragraph_sentence_count_first', 'paragraph_sentence_count_last',\n",
       "       'paragraph_error_count_q1', 'paragraph_error_count_q3',\n",
       "       'paragraph_char_count_q1', 'paragraph_char_count_q3',\n",
       "       'paragraph_word_count_q1', 'paragraph_word_count_q3',\n",
       "       'paragraph_sentence_count_q1', 'paragraph_sentence_count_q3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>paragraph_error_count_mean</th>\n",
       "      <th>paragraph_error_count_min</th>\n",
       "      <th>paragraph_error_count_max</th>\n",
       "      <th>paragraph_error_count_sum</th>\n",
       "      <th>paragraph_error_count_first</th>\n",
       "      <th>paragraph_error_count_last</th>\n",
       "      <th>paragraph_char_count_mean</th>\n",
       "      <th>paragraph_char_count_min</th>\n",
       "      <th>paragraph_char_count_max</th>\n",
       "      <th>...</th>\n",
       "      <th>paragraph_sentence_count_first</th>\n",
       "      <th>paragraph_sentence_count_last</th>\n",
       "      <th>paragraph_error_count_q1</th>\n",
       "      <th>paragraph_error_count_q3</th>\n",
       "      <th>paragraph_char_count_q1</th>\n",
       "      <th>paragraph_char_count_q3</th>\n",
       "      <th>paragraph_word_count_q1</th>\n",
       "      <th>paragraph_word_count_q3</th>\n",
       "      <th>paragraph_sentence_count_q1</th>\n",
       "      <th>paragraph_sentence_count_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13643</th>\n",
       "      <td>c83d850</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>341.166667</td>\n",
       "      <td>62</td>\n",
       "      <td>546</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.75</td>\n",
       "      <td>215.0</td>\n",
       "      <td>473.75</td>\n",
       "      <td>42.25</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>357ce9b</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>403.800000</td>\n",
       "      <td>55</td>\n",
       "      <td>1009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>158.0</td>\n",
       "      <td>404.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>5b0af71</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>601.200000</td>\n",
       "      <td>416</td>\n",
       "      <td>883</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>443.0</td>\n",
       "      <td>657.00</td>\n",
       "      <td>85.00</td>\n",
       "      <td>113.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  paragraph_error_count_mean  paragraph_error_count_min  \\\n",
       "13643  c83d850                    1.166667                          0   \n",
       "3610   357ce9b                    2.400000                          0   \n",
       "6088   5b0af71                    3.200000                          1   \n",
       "\n",
       "       paragraph_error_count_max  paragraph_error_count_sum  \\\n",
       "13643                          3                          7   \n",
       "3610                           6                         12   \n",
       "6088                           7                         16   \n",
       "\n",
       "       paragraph_error_count_first  paragraph_error_count_last  \\\n",
       "13643                            2                           0   \n",
       "3610                             0                           1   \n",
       "6088                             2                           1   \n",
       "\n",
       "       paragraph_char_count_mean  paragraph_char_count_min  \\\n",
       "13643                 341.166667                        62   \n",
       "3610                  403.800000                        55   \n",
       "6088                  601.200000                       416   \n",
       "\n",
       "       paragraph_char_count_max  ...  paragraph_sentence_count_first  \\\n",
       "13643                       546  ...                               5   \n",
       "3610                       1009  ...                               0   \n",
       "6088                        883  ...                               4   \n",
       "\n",
       "       paragraph_sentence_count_last  paragraph_error_count_q1  \\\n",
       "13643                              5                      0.25   \n",
       "3610                               3                      1.00   \n",
       "6088                               6                      2.00   \n",
       "\n",
       "       paragraph_error_count_q3  paragraph_char_count_q1  \\\n",
       "13643                      1.75                    215.0   \n",
       "3610                       4.00                    158.0   \n",
       "6088                       3.00                    443.0   \n",
       "\n",
       "       paragraph_char_count_q3  paragraph_word_count_q1  \\\n",
       "13643                   473.75                    42.25   \n",
       "3610                    404.00                    25.00   \n",
       "6088                    657.00                    85.00   \n",
       "\n",
       "       paragraph_word_count_q3  paragraph_sentence_count_q1  \\\n",
       "13643                     89.0                         1.25   \n",
       "3610                      71.0                         2.00   \n",
       "6088                     113.0                         6.00   \n",
       "\n",
       "       paragraph_sentence_count_q3  \n",
       "13643                          4.5  \n",
       "3610                           4.0  \n",
       "6088                           8.0  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_features.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Construct sentences\n",
    "    df[\"sentence\"] = df[\"full_text\"].map(lambda x: sent_tokenize(x))\n",
    "\n",
    "    # Have each paragraph be its own row\n",
    "    df = df.explode(\"sentence\")\n",
    "\n",
    "    # Process Paragraph text\n",
    "    df[\"sentence\"] = df[\"sentence\"].map(data_preprocessing)\n",
    "    df[\"sentence_no_punctuation\"] = df[\"sentence\"].map(remove_punctuation)\n",
    "\n",
    "    # Calculate base stats\n",
    "    df[\"sentence_error_count\"] = df[\"sentence_no_punctuation\"].map(count_spelling_errors)\n",
    "    df[\"sentence_char_count\"] = df[\"sentence\"].map(lambda x: len(x))\n",
    "    df[\"sentence_word_count\"] = df[\"sentence\"].map(lambda x: len(re.findall(r'\\w+', x)))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330422, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_features = process_sentence(train_df)\n",
    "sentence_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    feature_list = [\n",
    "        \"sentence_error_count\",\n",
    "        \"sentence_char_count\",\n",
    "        \"sentence_word_count\",\n",
    "    ]\n",
    "\n",
    "    feature_df = df.groupby(\"essay_id\")[feature_list].agg(\n",
    "        [\"mean\", \"min\", \"max\", \"sum\", \"first\", \"last\"]\n",
    "    )\n",
    "\n",
    "    feature_df = pd.concat(\n",
    "        [\n",
    "            feature_df,\n",
    "            df.groupby(\"essay_id\")[feature_list]\n",
    "            .agg([lambda x: np.quantile(x, 0.25), lambda x: np.quantile(x, 0.75)])\n",
    "            .rename(columns={\"<lambda_0>\": \"q1\", \"<lambda_1>\": \"q3\"}),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    feature_df = feature_df.set_axis(feature_df.columns.map(\"_\".join), axis=1)\n",
    "    return feature_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_features = sentence_feature_engineering(sentence_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>sentence_error_count_mean</th>\n",
       "      <th>sentence_error_count_min</th>\n",
       "      <th>sentence_error_count_max</th>\n",
       "      <th>sentence_error_count_sum</th>\n",
       "      <th>sentence_error_count_first</th>\n",
       "      <th>sentence_error_count_last</th>\n",
       "      <th>sentence_char_count_mean</th>\n",
       "      <th>sentence_char_count_min</th>\n",
       "      <th>sentence_char_count_max</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_word_count_max</th>\n",
       "      <th>sentence_word_count_sum</th>\n",
       "      <th>sentence_word_count_first</th>\n",
       "      <th>sentence_word_count_last</th>\n",
       "      <th>sentence_error_count_q1</th>\n",
       "      <th>sentence_error_count_q3</th>\n",
       "      <th>sentence_char_count_q1</th>\n",
       "      <th>sentence_char_count_q3</th>\n",
       "      <th>sentence_word_count_q1</th>\n",
       "      <th>sentence_word_count_q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>1cbab90</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178.583333</td>\n",
       "      <td>59</td>\n",
       "      <td>264</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>723</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.5</td>\n",
       "      <td>218.0</td>\n",
       "      <td>25.75</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912</th>\n",
       "      <td>eadfbe2</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.333333</td>\n",
       "      <td>15</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>477</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>85.5</td>\n",
       "      <td>6.00</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>3605e2a</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>35</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>245</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>99.5</td>\n",
       "      <td>14.00</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  sentence_error_count_mean  sentence_error_count_min  \\\n",
       "1878   1cbab90                   0.625000                         0   \n",
       "15912  eadfbe2                   0.769231                         0   \n",
       "3643   3605e2a                   0.357143                         0   \n",
       "\n",
       "       sentence_error_count_max  sentence_error_count_sum  \\\n",
       "1878                          2                        15   \n",
       "15912                         4                        30   \n",
       "3643                          1                         5   \n",
       "\n",
       "       sentence_error_count_first  sentence_error_count_last  \\\n",
       "1878                            0                          0   \n",
       "15912                           1                          0   \n",
       "3643                            0                          1   \n",
       "\n",
       "       sentence_char_count_mean  sentence_char_count_min  \\\n",
       "1878                 178.583333                       59   \n",
       "15912                 62.333333                       15   \n",
       "3643                  87.000000                       35   \n",
       "\n",
       "       sentence_char_count_max  ...  sentence_word_count_max  \\\n",
       "1878                       264  ...                       45   \n",
       "15912                      189  ...                       38   \n",
       "3643                       147  ...                       31   \n",
       "\n",
       "       sentence_word_count_sum  sentence_word_count_first  \\\n",
       "1878                       723                         26   \n",
       "15912                      477                         19   \n",
       "3643                       245                         14   \n",
       "\n",
       "       sentence_word_count_last  sentence_error_count_q1  \\\n",
       "1878                         29                      0.0   \n",
       "15912                         9                      0.0   \n",
       "3643                         22                      0.0   \n",
       "\n",
       "       sentence_error_count_q3  sentence_char_count_q1  \\\n",
       "1878                       1.0                   154.5   \n",
       "15912                      1.0                    33.0   \n",
       "3643                       1.0                    71.5   \n",
       "\n",
       "       sentence_char_count_q3  sentence_word_count_q1  sentence_word_count_q3  \n",
       "1878                    218.0                   25.75                    38.0  \n",
       "15912                    85.5                    6.00                    16.5  \n",
       "3643                     99.5                   14.00                    20.5  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_features.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Get words\n",
    "    temp = df[\"full_text\"].map(data_preprocessing)\n",
    "    df[\"word\"] = temp.map(lambda x: x.split(\" \"))\n",
    "\n",
    "    # Have each paragraph be its own row\n",
    "    df = df.explode(\"word\")\n",
    "\n",
    "    # Calculate base stats\n",
    "    df[\"word_char_count\"] = df[\"word\"].map(lambda x: len(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6350538, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features = process_word(train_df)\n",
    "word_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    feature_list = [\"word_char_count\"]\n",
    "\n",
    "    feature_df = df.groupby(\"essay_id\")[feature_list].agg([\"mean\", \"min\", \"max\"])\n",
    "\n",
    "    feature_df = pd.concat(\n",
    "        [\n",
    "            feature_df,\n",
    "            df.groupby(\"essay_id\")[feature_list]\n",
    "            .agg(\n",
    "                [\n",
    "                    lambda x: np.quantile(x, 0.25),\n",
    "                    lambda x: np.quantile(x, 0.50),\n",
    "                    lambda x: np.quantile(x, 0.75),\n",
    "                ]\n",
    "            )\n",
    "            .rename(\n",
    "                columns={\n",
    "                    \"<lambda_0>\": \"q1\",\n",
    "                    \"<lambda_1>\": \"q2\",\n",
    "                    \"<lambda_1>\": \"q3\",\n",
    "                }\n",
    "            ),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    feature_df = feature_df.set_axis(feature_df.columns.map(\"_\".join), axis=1)\n",
    "    feature_df = pd.concat([feature_df, df.groupby(\"essay_id\")[\"score\"].mean()], axis=1)\n",
    "    return feature_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features = word_feature_engineering(word_features)\n",
    "word_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Features\n",
    "\n",
    "A TF-IDF vectorizer is used to convert the essays into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    strip_accents=\"unicode\",\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(3, 6),\n",
    "    min_df=0.05,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features = vectorizer.fit_transform([i for i in train_df['full_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 19627)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features = pd.DataFrame(tfidf_features.toarray())\n",
    "tfidf_features.columns = [f\"tfidf_{i}\" for i in range(tfidf_features.shape[1])]\n",
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_features[\"essay_id\"] = train_df[\"essay_id\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Vectorizer\n",
    "\n",
    "A countVectorizer is used to convert the essays into numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_cnt = CountVectorizer(\n",
    "    tokenizer=lambda x: x,\n",
    "    preprocessor=lambda x: x,\n",
    "    token_pattern=None,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(2,3),\n",
    "    min_df=0.10,\n",
    "    max_df=0.85,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_features = vectorizer_cnt.fit_transform([i for i in train_df['full_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17307, 2170)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_features = pd.DataFrame(count_features.toarray())\n",
    "count_features.columns = [f\"tfidf_count_{i}\" for i in range(count_features.shape[1])]\n",
    "count_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_features[\"essay_id\"] = train_df[\"essay_id\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeBERTA Predictions\n",
    "\n",
    "Predictions made using DeBERTA models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23811, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov_path = \"output/microsoft/deberta-v3-xsmall/oof_df.csv\"\n",
    "deberta_features = pd.read_csv(oov_path, usecols=[f\"score_prob_{i}\" for i in range(config.num_classes)] + [\"essay_id\"])\n",
    "deberta_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>score_prob_0</th>\n",
       "      <th>score_prob_1</th>\n",
       "      <th>score_prob_2</th>\n",
       "      <th>score_prob_3</th>\n",
       "      <th>score_prob_4</th>\n",
       "      <th>score_prob_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10141</th>\n",
       "      <td>6ed94f5</td>\n",
       "      <td>-3.045542</td>\n",
       "      <td>-3.267240</td>\n",
       "      <td>-1.664371</td>\n",
       "      <td>0.658285</td>\n",
       "      <td>2.745111</td>\n",
       "      <td>2.705156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15542</th>\n",
       "      <td>a698bb4</td>\n",
       "      <td>-1.512836</td>\n",
       "      <td>2.838059</td>\n",
       "      <td>3.235294</td>\n",
       "      <td>0.125551</td>\n",
       "      <td>-2.400192</td>\n",
       "      <td>-2.780882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21911</th>\n",
       "      <td>eafac49</td>\n",
       "      <td>-0.380366</td>\n",
       "      <td>1.164232</td>\n",
       "      <td>2.426566</td>\n",
       "      <td>1.046173</td>\n",
       "      <td>-1.295725</td>\n",
       "      <td>-2.493743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  score_prob_0  score_prob_1  score_prob_2  score_prob_3  \\\n",
       "10141  6ed94f5     -3.045542     -3.267240     -1.664371      0.658285   \n",
       "15542  a698bb4     -1.512836      2.838059      3.235294      0.125551   \n",
       "21911  eafac49     -0.380366      1.164232      2.426566      1.046173   \n",
       "\n",
       "       score_prob_4  score_prob_5  \n",
       "10141      2.745111      2.705156  \n",
       "15542     -2.400192     -2.780882  \n",
       "21911     -1.295725     -2.493743  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta_features.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23810, 21867)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = deberta_features.copy()\n",
    "\n",
    "# Merge using essay_id column\n",
    "for feature_df in [paragraph_features, sentence_features, word_features, tfidf_features, count_features]:\n",
    "    all_features = pd.merge(all_features, feature_df, on=\"essay_id\")\n",
    "\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.drop_duplicates(subset=\"essay_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features.to_csv(Paths.FEATURE_ENGG_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
