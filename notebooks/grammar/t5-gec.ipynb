{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Correction\n",
    "\n",
    "[Thanks to Theitcrow's notebook](https://www.kaggle.com/code/kevinbnisch/grammar-errors-threshold-and-features-aes/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, AutoConfig\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.paths import Paths\n",
    "from lib.utils.utils import seed_everything\n",
    "from lib.model.gec import correct_sentence, process_sentence, correct_all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \n",
    "1. https://huggingface.co/juancavallotti/t5-base-gec\n",
    "2. https://huggingface.co/shashank2123/t5-finetuned-for-GEC\n",
    "3. https://huggingface.co/fenffef/t5-base-gec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Unbabel/gec-t5_small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Unbabel/gec-t5_small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output/T5/tokenizer/tokenizer_config.json',\n",
       " 'output/T5/tokenizer/special_tokens_map.json',\n",
       " 'output/T5/tokenizer/spiece.model',\n",
       " 'output/T5/tokenizer/added_tokens.json',\n",
       " 'output/T5/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"output/T5\")\n",
    "tokenizer.save_pretrained(\"output/T5/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When I grow up, I start to understand what he said is quite right.',\n",
       " 'When I grow up, I start to understand what he said is quite right.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    [\n",
    "        \"When I grow up, I starti to understand what he said is quite right.\",\n",
    "        \"When I grow up, I starti to understand what he said is quite right.\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    Paths.COMPETITION_TRAIN_CSV_PATH,\n",
    "    usecols=[\"essay_id\", \"full_text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330422, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = process_sentence(train_df.copy(deep=True))\n",
    "sentence_df.drop(columns=[\"full_text\"], inplace=True)\n",
    "sentence_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    train_df.essay_id.unique().shape == sentence_df.essay_id.unique().shape\n",
    "), f\"Expected: {train_df.essay_id.unique().shape}, Got: {sentence_df.essay_id.unique().shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df[\"len\"] = sentence_df.sentence.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.drop(index=sentence_df[(sentence_df.len < 10)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    train_df.essay_id.unique().shape == sentence_df.essay_id.unique().shape\n",
    "), f\"Expected: {train_df.essay_id.unique().shape}, Got: {sentence_df.essay_id.unique().shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df[\"corrected\"]  = correct_all_sentences(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    sentence_df,\n",
    "    batch_size=2048,\n",
    ")\n",
    "\n",
    "sentence_df[\"corrected\"].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.loc[sentence_df.corrected.isna(), \"corrected\"] = sentence_df.loc[\n",
    "    sentence_df.corrected.isna(), \"sentence\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df[\"corrected\"] = sentence_df[\"corrected\"].map(post_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    train_df.essay_id.unique().shape == sentence_df.essay_id.unique().shape\n",
    "), f\"Expected: {train_df.essay_id.unique().shape}, Got: {sentence_df.essay_id.unique().shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26       Many people in todays society tend to travel b...\n",
       "348      In the article \"The Challenge of Exploring Ven...\n",
       "349      a computer can not tell if your happy or if yo...\n",
       "431      Kids across America probably know someone who ...\n",
       "568      The advantages of limiting car is great becaus...\n",
       "                               ...                        \n",
       "15453    The electorian collage is a very popular thing...\n",
       "15465    The future iscoming soon everday. And everyday...\n",
       "15852    In the article \"The Challenge of Exploring Ven...\n",
       "16663    The author supports people to study Venus is b...\n",
       "16856    Being able to detect other peoples and even yo...\n",
       "Name: full_text, Length: 97, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[~train_df.index.isin(sentence_df.index), \"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.to_csv(\n",
    "    \"data/feature_engg/grammar_correct.csv\",\n",
    "    index=False,\n",
    "    columns=[\"essay_id\", \"sentence\", \"corrected\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
