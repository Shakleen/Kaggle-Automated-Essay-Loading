{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar Correction\n",
    "\n",
    "[Thanks to Theitcrow's notebook](https://www.kaggle.com/code/kevinbnisch/grammar-errors-threshold-and-features-aes/notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, AutoConfig\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.paths import Paths\n",
    "from lib.utils.utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \n",
    "1. https://huggingface.co/juancavallotti/t5-base-gec\n",
    "2. https://huggingface.co/shashank2123/t5-finetuned-for-GEC\n",
    "3. https://huggingface.co/fenffef/t5-base-gec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Unbabel/gec-t5_small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"Unbabel/gec-t5_small\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output/T5/tokenizer/tokenizer_config.json',\n",
       " 'output/T5/tokenizer/special_tokens_map.json',\n",
       " 'output/T5/tokenizer/spiece.model',\n",
       " 'output/T5/tokenizer/added_tokens.json',\n",
       " 'output/T5/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"output/T5\")\n",
    "tokenizer.save_pretrained(\"output/T5/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sentence(sentences):\n",
    "    sentences = [\n",
    "        f\"Fix grammatical errors, if any, in this sentence: {sentence}\"\n",
    "        for sentence in sentences\n",
    "    ]\n",
    "    input_ids = tokenizer(\n",
    "        sentences,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "    ).input_ids.to(device)\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    del input_ids\n",
    "    corrected_sentences = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    del outputs\n",
    "    return corrected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When I grow up, I start to understand what he said is quite right.',\n",
       " 'When I grow up, I start to understand what he said is quite right.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sentence([\n",
    "    \"When I grow up, I starti to understand what he said is quite right.\",\n",
    "    \"When I grow up, I starti to understand what he said is quite right.\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\n",
    "    Paths.COMPETITION_TRAIN_CSV_PATH,\n",
    "    usecols=[\"essay_id\", \"full_text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(x: str) -> str:\n",
    "    x = re.sub(r\"<[^>]*>\", \"\", x)\n",
    "    x = re.sub(\"@\\w+\", \"\", x)\n",
    "    x = re.sub(\"'\\d+\", \"\", x)\n",
    "    x = re.sub(\"\\d+\", \"\", x)\n",
    "    x = re.sub(r\"http\\S+\", \"\", x)\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    x = re.sub(r\"\\.+\", \".\", x)\n",
    "    x = re.sub(r\"\\,+\", \",\", x)\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"sentence\"] = df[\"full_text\"].map(lambda x: sent_tokenize(x))\n",
    "    df = df.explode(\"sentence\").reset_index(drop=True)\n",
    "    df[\"sentence\"] = df[\"sentence\"].map(data_preprocessing)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330422, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df = process_sentence(train_df.copy(deep=True))\n",
    "sentence_df.drop(columns=[\"full_text\"], inplace=True)\n",
    "sentence_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    train_df.essay_id.unique().shape == sentence_df.essay_id.unique().shape\n",
    "), f\"Expected: {train_df.essay_id.unique().shape}, Got: {sentence_df.essay_id.unique().shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df[\"len\"] = sentence_df.sentence.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.drop(index=sentence_df[(sentence_df.len < 10)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    train_df.essay_id.unique().shape == sentence_df.essay_id.unique().shape\n",
    "), f\"Expected: {train_df.essay_id.unique().shape}, Got: {sentence_df.essay_id.unique().shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_sentences = None\n",
    "\n",
    "for i in range(0, sentence_df.shape[0], batch_size):\n",
    "    start, end = i, i + batch_size\n",
    "    sentences = sentence_df[\"sentence\"].iloc[start:end]\n",
    "    corrected = correct_sentence(sentences)\n",
    "    corrected = np.array(corrected).flatten()\n",
    "\n",
    "    if corrected_sentences is None:\n",
    "        corrected_sentences = corrected\n",
    "    else:\n",
    "        corrected_sentences = np.hstack([corrected_sentences, corrected]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328524,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Many people have cars where they live.',\n",
       "       \"The thing they don't know is that when you use a car a lot of things can happen like you can get inaccidet or the smoke that the car has is bad to breathe on if someone is walking, but in VAUBAN, Germany they don't have that problem because percent of Vauban's families do not own cars, and percent sell a car to move there.\",\n",
       "       'Fix grammatical errors, if any, in this sentence: Street parking, driveways and home garages are forbidden on the outskirts of a neighbourhood near the French and Swiss borders.',\n",
       "       'You probably won\\'t see a car in Vauban\\'s streets because they are completely \"car free\" but if some that lives in VAUBAN that owns car ownership is allowed, but there are only two places that you can park a large garage at the edge of the development, where a car owner buys a space but it is not cheap to buy one. They sell the space for your car for $, along with a home.',\n",
       "       'The vauban people completed this in, they said that this is an example of a growing trend in Europe. The vauban people completed this in, they said that this is an example of a growing trend in Europe. The vauban people completed this in. They said that this is an example of a growing trend in Europe. The vauban people completed this in. They said that this is an example of a growing trend in Europe. The until states and somewhere else are suburban life from auto use. This is called \"s',\n",
       "       'The current efforts to drastically reduce greenhouse gas emissions from tail the passengee cars are responsible for percent of greenhouse gas emissions in Europe and up to percent in some car intensive in the United States.',\n",
       "       'I honestly think that the good idea that they did is Vaudan because that makes cities denser and better for walking and in VAUBAN there are residents within a rectangular square mile.',\n",
       "       'In the article, David Goldberg said that \"All of our development since the World War has been centered on cars, and that will have to change\" and I think that was very true what David Gold said because a lot of things we need cars to do we can go anyway were without cars because some people are very lazy to walk to places. Thats why they a lot of people use cars and I think that it was a good idea that',\n",
       "       'It is good that they are doing that if you think about your help to the earth in a way and thats a very good thing to.',\n",
       "       'In the United States, the Environmental Protection Agency is promoting what is called \"car reduced\" communities, and the legislators are starting to act, if cautiously.'],\n",
       "      dtype='<U768')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df[\"corrected\"] = corrected_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>len</th>\n",
       "      <th>corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270156</th>\n",
       "      <td>d055690</td>\n",
       "      <td>The author is using a problem and solution met...</td>\n",
       "      <td>50</td>\n",
       "      <td>Fix grammatical errors, if any, in this senten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276314</th>\n",
       "      <td>d586afa</td>\n",
       "      <td>In the article of \"The Challenge of Exploring ...</td>\n",
       "      <td>186</td>\n",
       "      <td>In the article of \"The Challenge of Exploring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119894</th>\n",
       "      <td>5e20c0f</td>\n",
       "      <td>When student dont understand somthing this sys...</td>\n",
       "      <td>177</td>\n",
       "      <td>When students dont understand something, if an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id                                           sentence  len  \\\n",
       "270156  d055690  The author is using a problem and solution met...   50   \n",
       "276314  d586afa  In the article of \"The Challenge of Exploring ...  186   \n",
       "119894  5e20c0f  When student dont understand somthing this sys...  177   \n",
       "\n",
       "                                                corrected  \n",
       "270156  Fix grammatical errors, if any, in this senten...  \n",
       "276314  In the article of \"The Challenge of Exploring ...  \n",
       "119894  When students dont understand something, if an...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.loc[sentence_df.corrected.isna(), \"corrected\"] = sentence_df.loc[\n",
    "    sentence_df.corrected.isna(), \"sentence\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(text):\n",
    "    pattern = r\"sentence\\s*:\\s*\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE)\n",
    "\n",
    "    if match:\n",
    "        text = text[match.end():]\n",
    "        \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df[\"corrected\"] = sentence_df[\"corrected\"].map(post_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    train_df.essay_id.unique().shape == sentence_df.essay_id.unique().shape\n",
    "), f\"Expected: {train_df.essay_id.unique().shape}, Got: {sentence_df.essay_id.unique().shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26       Many people in todays society tend to travel b...\n",
       "348      In the article \"The Challenge of Exploring Ven...\n",
       "349      a computer can not tell if your happy or if yo...\n",
       "431      Kids across America probably know someone who ...\n",
       "568      The advantages of limiting car is great becaus...\n",
       "                               ...                        \n",
       "15453    The electorian collage is a very popular thing...\n",
       "15465    The future iscoming soon everday. And everyday...\n",
       "15852    In the article \"The Challenge of Exploring Ven...\n",
       "16663    The author supports people to study Venus is b...\n",
       "16856    Being able to detect other peoples and even yo...\n",
       "Name: full_text, Length: 97, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[~train_df.index.isin(sentence_df.index), \"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.to_csv(\n",
    "    \"data/feature_engg/grammar_correct.csv\",\n",
    "    index=False,\n",
    "    columns=[\"essay_id\", \"sentence\", \"corrected\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
